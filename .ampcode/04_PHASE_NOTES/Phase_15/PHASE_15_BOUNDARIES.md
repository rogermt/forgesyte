# â­ PHASE 15 â€” BOUNDARIES & GAPS

**Where Phase 14 Stops, Phase 15 Begins**

This document defines the exact boundary between Phase 14 and Phase 15 to prevent scope creep and ensure clean phase separation.

---

## Phase 14 Scope (What's IN)

âœ… **DAG Pipeline Definition**
- Graph structure (nodes, edges)
- Validation (cycles, types, structure)
- Registry (load from JSON)

âœ… **Single-Frame Execution**
- Execute pipeline once
- Return output once
- No state persistence

âœ… **REST API**
- POST /pipelines/{id}/run
- GET /pipelines/list
- GET /pipelines/{id}/info

âœ… **WebSocket Frame Handler**
- Accept frame, run pipeline, return result
- One frame â†’ one result

âœ… **Type Validation**
- Input/output type compatibility
- Prevent mismatched connections

âœ… **Tool Metadata**
- input_types, output_types
- capabilities, handler info

---

## Phase 15 Scope (What's OUT of Phase 14)

âŒ **Job Queuing** â† PHASE 15
- Multiple pipelines queued
- Async execution tracking
- Job status polling
- Job persistence

âŒ **Job Persistence** â† PHASE 15
- Store jobs in database
- Retrieve job history
- Job metadata

âŒ **Streaming Execution** â† PHASE 15
- Process video stream frame-by-frame
- Maintain state across frames
- Track object IDs across frames
- Accumulate results

âŒ **Pipeline History** â† PHASE 15
- Record all pipeline executions
- Search execution history
- Performance metrics per pipeline

âŒ **Performance Metrics** â† PHASE 15
- Execution time per node
- Throughput tracking
- Bottleneck detection

âŒ **Pipeline Versioning** â† PHASE 15
- Multiple versions of same pipeline
- Version selection in requests
- Version history

---

## Critical Phase 14 Boundaries

### 1. No Streaming

âŒ **WRONG** (Phase 15):
```python
async def stream_pipeline(pipeline_id, video_file):
    """Process entire video, accumulate results."""
    results = []
    for frame in video_file:
        results.append(await run_pipeline(pipeline_id, frame))
    return results
```

âœ… **RIGHT** (Phase 14):
```python
async def run_pipeline(pipeline_id, frame):
    """Process single frame, return result."""
    return await service.execute(pipeline, frame)
```

**Why**: Streaming requires job queuing, state management, persistence.

---

### 2. No Job Tracking

âŒ **WRONG** (Phase 15):
```python
# REST: Execute and poll for result
POST /pipelines/run â†’ returns job_id
GET /jobs/{job_id} â†’ returns status
```

âœ… **RIGHT** (Phase 14):
```python
# REST: Execute synchronously, return result immediately
POST /pipelines/run â†’ returns result directly
```

**Why**: Job tracking requires async backend, database, job manager.

---

### 3. No State Between Frames

âŒ **WRONG** (Phase 15):
```python
class PipelineExecutor:
    def __init__(self, pipeline_id):
        self.state = {}  # âŒ Persisted state
        
    async def process_frame(self, frame):
        # Use self.state for tracking
        self.state["previous_detections"] = ...
```

âœ… **RIGHT** (Phase 14):
```python
async def execute_pipeline(pipeline, frame):
    # Stateless execution
    # Each call is independent
    return result
```

**Why**: State persistence requires session management, database.

---

### 4. No Database Writes

âŒ **WRONG** (Phase 15):
```python
# Store every execution
await db.jobs.insert_one({
    "pipeline_id": pipeline_id,
    "timestamp": now(),
    "result": result
})
```

âœ… **RIGHT** (Phase 14):
```python
# Just log and return
logger.info(f"Pipeline {pipeline_id} executed")
return result
```

**Why**: Database writes require schema, migrations, persistence layer.

---

### 5. No Async Job Queue

âŒ **WRONG** (Phase 15):
```python
# Queue jobs for background processing
job = await job_manager.submit(pipeline_id, frame)
return {"job_id": job.id}  # Don't wait for result
```

âœ… **RIGHT** (Phase 14):
```python
# Execute immediately, return result
result = await service.execute(pipeline, frame)
return result  # Synchronous response
```

**Why**: Job queues require: async workers, job manager, Redis/RabbitMQ.

---

### 6. No Frame Accumulation

âŒ **WRONG** (Phase 15):
```python
results = []
for frame in video:
    result = await execute_pipeline(pipeline, frame)
    results.append(result)
return results
```

âœ… **RIGHT** (Phase 14):
```python
# Single frame at a time
result = await execute_pipeline(pipeline, frame)
return result
```

**Why**: Accumulation requires streaming architecture, state management.

---

## Exact API Boundary

### Phase 14 REST Endpoints

```
GET  /pipelines/list
     â””â”€ Returns: { pipelines: [...] }

GET  /pipelines/{id}/info
     â””â”€ Returns: { id, name, nodes, edges, ... }

POST /pipelines/{id}/run
     â”œâ”€ Input:  { image: "...", options: {...} }
     â””â”€ Returns: { status: "success", output: {...}, execution_time_ms: 425 }

POST /pipelines/validate
     â”œâ”€ Input:  { nodes: [...], edges: [...], ... }
     â””â”€ Returns: { valid: true/false, errors: [...] }
```

**What's NOT in Phase 14**:
- GET /jobs/{job_id} â† PHASE 15
- GET /jobs/list â† PHASE 15
- POST /jobs/{job_id}/cancel â† PHASE 15
- GET /pipelines/{id}/history â† PHASE 15
- GET /pipelines/{id}/metrics â† PHASE 15

---

## Exact WebSocket Boundary

### Phase 14 WebSocket Messages

**Send** (from client):
```json
{
  "type": "frame",
  "pipeline_id": "player_tracking_v1",
  "frame_id": "frame_001",
  "image": "base64_data"
}
```

**Receive** (from server):
```json
{
  "type": "result",
  "frame_id": "frame_001",
  "status": "success",
  "output": {...},
  "execution_time_ms": 425
}
```

**What's NOT in Phase 14**:
- Job status updates â† PHASE 15
- Stream start/stop messages â† PHASE 15
- Accumulated results â† PHASE 15
- State checkpoint messages â† PHASE 15

---

## Data Model Boundaries

### Phase 14 Models

```python
class Pipeline(BaseModel):
    id: str
    name: str
    nodes: List[PipelineNode]
    edges: List[PipelineEdge]
    entry_nodes: List[str]
    output_nodes: List[str]

class PipelineExecutionResult(BaseModel):
    status: str
    output: Dict
    execution_time_ms: float
    node_logs: List[Dict]
```

**What's NOT in Phase 14**:
```python
class Job(BaseModel):  # â† PHASE 15
    job_id: str
    pipeline_id: str
    status: str
    submitted_at: datetime
    completed_at: Optional[datetime]
    result: Optional[Dict]
    error: Optional[str]

class PipelineMetrics(BaseModel):  # â† PHASE 15
    pipeline_id: str
    execution_count: int
    average_time_ms: float
    slowest_node_id: str
```

---

## Configuration Boundaries

### Phase 14 Configuration

```python
# app/config.py
PIPELINES_DIR = "app/pipelines"  # Where pipeline JSON lives
MAX_PIPELINE_NODES = 100
MAX_EXECUTION_TIME_MS = 60000
```

**What's NOT in Phase 14**:
```python
# â† PHASE 15
JOB_QUEUE_URL = "redis://localhost:6379"
DB_CONNECTION_STRING = "postgresql://..."
JOB_RETENTION_DAYS = 30
MAX_CONCURRENT_JOBS = 10
```

---

## Testing Boundaries

### Phase 14 Tests

```python
# tests/pipelines/test_pipeline_execution.py
async def test_single_frame_execution():
    """Execute pipeline once, get result."""
    
# tests/pipelines/test_pipeline_validation.py
def test_rejects_cycles():
    """Validate pipeline structure."""
    
# tests/pipelines/test_pipeline_endpoints.py
async def test_rest_run_endpoint():
    """POST /pipelines/{id}/run works."""
```

**What's NOT in Phase 14**:
```python
# â† PHASE 15
async def test_job_queue():
    """Jobs can be queued and polled."""
    
async def test_streaming_execution():
    """Video stream is processed frame by frame."""
    
async def test_pipeline_metrics():
    """Performance metrics are tracked."""
```

---

## Feature Checklist: What Stays OUT

| Feature | Phase | Status |
|---------|-------|--------|
| Single frame execution | 14 | âœ… IN |
| DAG validation | 14 | âœ… IN |
| Type checking | 14 | âœ… IN |
| REST API | 14 | âœ… IN |
| WebSocket support | 14 | âœ… IN |
| **Job queuing** | **15** | âŒ OUT |
| **Async execution** | **15** | âŒ OUT |
| **Job persistence** | **15** | âŒ OUT |
| **Video streaming** | **15** | âŒ OUT |
| **State management** | **15** | âŒ OUT |
| **Performance metrics** | **15** | âŒ OUT |
| **Pipeline history** | **15** | âŒ OUT |
| **Pipeline versioning** | **15** | âŒ OUT |

---

## The Clean Handoff

### Phase 14 Guarantees

âœ… Single pipeline execution works  
âœ… Multiple frames can be sent sequentially  
âœ… Each frame gets independent result  
âœ… No frame affects another  
âœ… Stateless execution  

### What Phase 15 Will Add

â• Queue multiple frames  
â• Track job progress  
â• Persist results  
â• Accumulate across frames  
â• Performance analytics  

### The Boundary

**Phase 14 = Single Frame**  
**Phase 15 = Multiple Frames with State**

---

## Why This Boundary?

### Phase 14 Complexity
- DAG validation: **HARD**
- Cross-plugin execution: **HARD**
- Type checking: **MEDIUM**
- Single frame execution: **EASY**

### Phase 15 Complexity
- Job queuing: **HARD**
- State management: **HARD**
- Persistence: **MEDIUM**
- Streaming: **EASY** (once Phase 14 works)

**Decision**: Keep Phase 14 focused on pipeline mechanics, let Phase 15 handle scaling.

---

## Phase 14 Definition of Done

âœ… One frame â†’ One result (guaranteed)  
âœ… Multiple frames work sequentially (each independent)  
âœ… Validate before execute (always)  
âœ… Type contracts enforced (always)  
âœ… REST API functional (always)  
âœ… WebSocket support works (always)  
âœ… 85%+ test coverage (always)  
âœ… Zero state across calls (always)  

**NOT** in Definition of Done:
- Queuing systems
- Persistence layers
- Streaming architectures
- State tracking
- Performance metrics

---

## Red Flags for Scope Creep

If you see these during Phase 14, they belong in Phase 15:

ğŸš¨ "We need to store job results" â†’ PHASE 15  
ğŸš¨ "We need to track job status" â†’ PHASE 15  
ğŸš¨ "We need to process video streams" â†’ PHASE 15  
ğŸš¨ "We need to track state between frames" â†’ PHASE 15  
ğŸš¨ "We need async job workers" â†’ PHASE 15  
ğŸš¨ "We need performance metrics" â†’ PHASE 15  
ğŸš¨ "We need to accumulate results" â†’ PHASE 15  

If someone suggests one of these: **"That's Phase 15. Phase 14 is single-frame only."**

---

## Summary

**Phase 14**: Transform single-plugin to multi-plugin DAG execution  
**Phase 15**: Transform single-frame to multi-frame with state/queuing

**The boundary is clear**: Frame-level execution vs. Job-level management

**No ambiguity**: If it requires queuing, persistence, or state â†’ Phase 15
