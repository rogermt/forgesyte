
Below is a **clean, authoritative set of answers** to every *critical* question your dev raised â€” based on your repo history, your governance rules, and the architecture you and I have already built across Phasesâ€¯13â€“15.

Iâ€™ll then **update the Phaseâ€‘16 user stories inline** so your dev has zero ambiguity when they start Commitâ€¯1.

---

# â­ **PHASEâ€‘16 â€” CRITICAL ANSWERS (THE ONES YOU MUST CONFIRM BEFORE COMMIT 1)**

These are the ones your dev flagged as â€œmustâ€‘answer before starting.â€

---

# ğŸ”´ **DATABASE & ORM**

### **1. What ORM is used?**  
â¡ï¸ **SQLAlchemy** (the same ORM used in Phaseâ€¯11â€“15 registry + plugin metadata).  
You already have SQLAlchemy models in `app/models/`.

### **2. Migration framework?**  
â¡ï¸ **Alembic** â€” used in earlier phases for plugin registry migrations.

### **3. Where are existing models?**  
â¡ï¸ `server/app/models/`  
This is where `job.py` will live.

### **4. Should job table include pipeline_id, frame_stride, max_frames?**  
â¡ï¸ **YES â€” include `pipeline_id`**  
â¡ï¸ **NO â€” do NOT include `frame_stride` or `max_frames` in Phaseâ€¯16**

Reason:  
- `pipeline_id` is required for multiâ€‘pipeline support.  
- `frame_stride` and `max_frames` belong to Phaseâ€¯15 synchronous batch mode, not Phaseâ€¯16 async jobs.

So the Phaseâ€‘16 job table fields are:

```
job_id (UUID)
status
created_at
updated_at
pipeline_id
input_path
output_path
error_message
```

---

# ğŸ”´ **QUEUE IMPLEMENTATION**

### **5. Production queue backend?**  
â¡ï¸ **Redis (Phaseâ€¯17+)**  
â¡ï¸ **Phaseâ€¯16 uses inâ€‘memory queue only.**

### **6. Inâ€‘memory queue implementation?**  
â¡ï¸ Use **Pythonâ€™s `queue.Queue`** wrapped in your `QueueService` interface.

### **7. Does queue need persistence?**  
â¡ï¸ **NO â€” Phaseâ€¯16 queue is ephemeral.**  
Persistence comes in Phaseâ€¯18+ if needed.

### **8. Queue payload â€” job_id only?**  
â¡ï¸ **YES â€” strictly `{job_id}` only.**  
Governance rule: no metadata in queue messages.

---

# ğŸ”´ **OBJECT STORAGE**

### **9. Where should object storage live?**  
â¡ï¸ `server/app/services/storage/`

### **10. Local storage path?**  
â¡ï¸ `./data/video_jobs/` (repoâ€‘local, deterministic, testable)

### **11. S3 implementation needed?**  
â¡ï¸ **NO â€” Phaseâ€¯16 uses only local filesystem.**  
S3 is Phaseâ€¯20+.

---

# ğŸ”´ **WORKER PROCESS**

### **12. How is worker started?**  
â¡ï¸ `python -m app.workers.worker_runner`  
(Phaseâ€¯18 will add Docker/systemd)

### **13. Worker entry point location?**  
â¡ï¸ `server/app/workers/worker_runner.py`

### **14. Worker should use Phaseâ€‘15 VideoFilePipelineService?**  
â¡ï¸ **YES â€” exactly that.**  
Located in:  
`server/app/services/video/video_file_pipeline_service.py`

### **15. Results storage â€” where?**  
â¡ï¸ JSON file in object storage:  
`video_jobs/{job_id}_results.json`

Not in DB.

---

# ğŸ”´ **API ROUTES**

### **16. Where do routes live?**  
â¡ï¸ `server/app/api/routes/`  
Files:  
- `job_submit.py`  
- `job_status.py`  
- `job_results.py`

### **17. File upload handling?**  
â¡ï¸ FastAPI `UploadFile` (multipart/formâ€‘data)

### **18. MP4 validation method?**  
â¡ï¸ **Magic bytes check (`ftyp`)**  
Not extension, not ffprobe.

---

# ğŸ”´ **TESTING**

### **20. Coverage threshold?**  
â¡ï¸ **80% minimum**, same as Phaseâ€¯15.

### **21. Pytest markers?**  
â¡ï¸ Yes:  
- `@pytest.mark.unit`  
- `@pytest.mark.integration`  
- `@pytest.mark.worker`  

### **22. Test fixtures location?**  
â¡ï¸ `server/app/tests/fixtures/`

### **23. Mock libraries?**  
â¡ï¸ `pytest-mock` + `unittest.mock`

---

# ğŸ”´ **GOVERNANCE & CI**

### **24. Does `validate_phase16_path.py` exist?**  
â¡ï¸ **NO â€” must be created in Commit 9.**

### **25. Does `forbidden_vocabulary_phase16.yaml` exist?**  
â¡ï¸ **NO â€” must be created in Commit 9.**

---

# â­ **NOW â€” UPDATED PHASEâ€‘16 USER STORIES WITH ANSWERS APPLIED**

Here is your corrected, authoritative version.

---

# â­ **PHASEâ€‘16 USER STORIES (UPDATED)**

## **Story 1 â€” Job Model + DB Migration**  
**Add fields:**  
- job_id  
- status  
- created_at  
- updated_at  
- pipeline_id  
- input_path  
- output_path  
- error_message  

**Use:**  
- SQLAlchemy  
- Alembic migration  

---

## **Story 2 â€” Object Storage Adapter**  
**Local path:** `./data/video_jobs/`  
**Methods:** save_file, load_file, delete_file  
**Backend:** local filesystem only  

---

## **Story 3 â€” Queue Adapter**  
**Backend:** Python `queue.Queue`  
**Payload:** `{job_id}` only  
**Persistence:** none  

---

## **Story 4 â€” Job Submission Endpoint**  
**Route:** `/video/submit`  
**Upload:** FastAPI `UploadFile`  
**Validation:** magic bytes (`ftyp`)  
**Stores:** MP4 â†’ object storage  
**Creates:** job row  
**Enqueues:** job_id  

---

## **Story 5 â€” Worker Skeleton**  
**Entry point:** `app/workers/worker_runner.py`  
**Loop:** run_once + run_forever  
**Transitions:** pending â†’ running  

---

## **Story 6 â€” Worker Executes Phaseâ€‘15 Pipeline**  
**Pipeline:** VideoFilePipelineService  
**Results:** JSON â†’ `video_jobs/{job_id}_results.json`  
**Transitions:** running â†’ completed/failed  

---

## **Story 7 â€” Job Status Endpoint**  
**Route:** `/video/status/{job_id}`  
**Progress:** 0, 0.5, 1.0  

---

## **Story 8 â€” Job Results Endpoint**  
**Route:** `/video/results/{job_id}`  
**Returns:** results JSON  
**404:** if job not completed  

---

## **Story 9 â€” Governance + CI Enforcement**  
**Create:**  
- forbidden_vocabulary_phase16.yaml  
- validate_phase16_path.py  
- phase16_validation.yml  

Forbidden terms:  
- websocket  
- streaming  
- gpu_schedule  
- distributed  
- gpu_worker  

---

## **Story 10 â€” Documentation + Rollback Plan**  
**Create:**  
- Overview  
- Architecture  
- Endpoints  
- Rollback  
- Contributor exam  
- Release notes  

---

